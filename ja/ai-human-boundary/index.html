<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <title>ai-human-boundary - VCDesign</title>
    <meta name="description" content="AI と人が一緒に価値を選ぶための境界ガイド。AI時代に人が壊れないための理解のガイド。">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        :root {
            --bg-base: #0a0a0c;
            --accent: #818CF8;
            --text-main: #E2E8F0;
            --text-muted: #94A3B8;
            --link-hover-bg: rgba(129, 140, 248, 0.08);
            --transition-fast: 0.18s ease-out;
            --line-color: rgba(129, 140, 248, 0.3);
        }

        * {
            box-sizing: border-box;
        }

        html,
        body {
            margin: 0;
            padding: 0;
            background-color: var(--bg-base);
            color: var(--text-main);
            font-family: system-ui, -apple-system, sans-serif;
            /* Gothic Base */
            line-height: 1.9;
            -webkit-font-smoothing: antialiased;
        }

        body {
            display: flex;
            justify-content: center;
        }

        /* Navigation */
        .nav-back {
            position: fixed;
            top: 24px;
            left: 24px;
            text-decoration: none;
            color: var(--text-muted);
            font-size: 0.9rem;
            transition: color var(--transition-fast);
            z-index: 100;
            /* Enhanced Visibility */
            background: rgba(15, 23, 42, 0.8);
            padding: 8px 16px;
            border-radius: 999px;
            border: 1px solid var(--line-color);
        }

        .nav-back:hover {
            color: #F8FAFC;
            border-color: var(--accent);
        }

        @media (max-width: 900px) {
            .nav-back {
                position: absolute;
            }
        }

        main {
            max-width: 680px;
            /* Slightly wider to accommodate passing line comfortably */
            width: 100%;
            padding: 120px 24px 200px;
        }

        /* The Continuity Line Container */
        .narrative-stream {
            position: relative;
            border-left: 1px solid var(--line-color);
            padding-left: 48px;
            margin-left: 12px;
        }

        /* Chapters */
        section.chapter {
            margin-bottom: 160px;
            position: relative;
        }

        /* Station Dots */
        section.chapter::before {
            content: "";
            position: absolute;
            left: -53px;
            /* border 1px + padding 48px + radius 4px = ~53px center aligned */
            top: 1.2rem;
            /* Align with H1/H2 roughly */
            width: 9px;
            height: 9px;
            background-color: var(--bg-base);
            border: 2px solid var(--accent);
            border-radius: 50%;
            z-index: 10;
        }

        /* Typography */
        h1,
        h2,
        h3 {
            font-family: "Hiragino Mincho ProN", "Yu Mincho", "游明朝", "MS Mincho", serif;
            font-weight: 600;
            color: #F8FAFC;
            letter-spacing: 0.05em;
        }

        h1 {
            font-size: 2.0rem;
            margin: 0 0 40px;
            line-height: 1.4;
        }

        h2 {
            font-size: 1.5rem;
            margin: 60px 0 24px;
            padding-bottom: 12px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        h3 {
            font-size: 1.1rem;
            margin: 40px 0 16px;
            color: var(--text-main);
        }

        p {
            margin-bottom: 2em;
            text-align: justify;
        }

        ul {
            list-style: none;
            padding: 0;
            margin: 32px 0;
        }

        ul li {
            position: relative;
            padding-left: 1.5em;
            margin-bottom: 1em;
            color: #E2E8F0;
        }

        ul li::before {
            content: "—";
            position: absolute;
            left: 0;
            color: var(--text-muted);
        }

        /* Inline Links */
        p a,
        li a {
            color: var(--accent);
            text-decoration: underline;
            text-underline-offset: 4px;
            transition: color var(--transition-fast);
        }

        p a:hover,
        li a:hover {
            color: #C7D2FE;
        }

        blockquote {
            margin: 40px 0;
            padding: 2px 0 2px 24px;
            border-left: 2px solid var(--accent);
            color: var(--text-muted);
            font-style: italic;
        }

        strong {
            font-weight: 700;
            color: #fff;
        }

        hr {
            border: 0;
            height: 1px;
            background: var(--line-color);
            margin: 80px 0;
            opacity: 0.5;
        }

        /* Responsive */
        @media (max-width: 600px) {
            .narrative-stream {
                padding-left: 24px;
                border-left: 1px solid var(--line-color);
            }

            section.chapter::before {
                left: -29px;
            }

            h1 {
                font-size: 1.6rem;
            }
        }

        footer {
            margin-top: 120px;
            text-align: center;
            font-size: 0.85rem;
            color: var(--text-muted);
            opacity: 0.6;
        }
    </style>
    <style>
        /* Story Navigation */
        .story-nav {
            position: fixed;
            top: 50%;
            right: 48px;
            transform: translateY(-50%);
            display: flex;
            flex-direction: column;
            gap: 24px;
            z-index: 100;
        }

        /* Connecting Line */
        .story-nav::before {
            content: "";
            position: absolute;
            top: 10px;
            bottom: 10px;
            left: 6px;
            /* Center of 12px dot */
            width: 1px;
            background: linear-gradient(to bottom,
                    transparent,
                    var(--line-color) 15%,
                    var(--line-color) 85%,
                    transparent);
            z-index: -1;
        }

        .story-dot {
            position: relative;
            width: 13px;
            height: 13px;
            border-radius: 50%;
            background-color: var(--bg-base);
            border: 2px solid var(--text-muted);
            transition: all 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            cursor: pointer;
            opacity: 0.6;
        }

        .story-dot:hover {
            border-color: var(--accent);
            box-shadow: 0 0 12px rgba(129, 140, 248, 0.4);
            transform: scale(1.2);
            opacity: 1;
        }

        /* Tooltip */
        .story-dot::after {
            content: attr(data-title);
            position: absolute;
            top: 50%;
            right: 24px;
            transform: translateY(-50%) translateX(10px);
            background: rgba(15, 23, 42, 0.9);
            color: #F8FAFC;
            padding: 4px 12px;
            border-radius: 4px;
            font-size: 0.75rem;
            white-space: nowrap;
            opacity: 0;
            pointer-events: none;
            transition: all 0.2s ease-out;
            border: 1px solid rgba(255, 255, 255, 0.1);
            font-family: system-ui, sans-serif;
            letter-spacing: 0.05em;
        }

        .story-dot:hover::after {
            opacity: 1;
            transform: translateY(-50%) translateX(0);
        }

        @media (max-width: 1100px) {
            .story-nav {
                display: none;
                /* Hide on smaller screens to avoid overlap */
            }
        }
    </style>
</head>

<body>
    <a href="../index.html" class="nav-back">← Home</a>

    <main>
        <div class="narrative-stream">

            <!-- Prelude: README.ja.md -->
            <section class="chapter" id="prelude">
                <h1>ai-human-boundary</h1>
                <p><strong>AI と人が一緒に価値を選ぶための境界ガイド</strong></p>

                <p>このリポジトリは、<br>
                    <strong>AI → 人</strong> ではなく<br>
                    <strong>AI＋人 → 価値</strong><br>
                    という関係を前提に、
                </p>

                <blockquote>
                    人が AI と付き合うときに、<br>
                    最低限「知っておくべき境界」
                </blockquote>

                <p>を整理・記録するためのものです。</p>

                <hr>

                <h2>このリポジトリは何か</h2>

                <p>このリポジトリは、</p>
                <ul>
                    <li>AI を賢く使う方法</li>
                    <li>AI に任せるための設計</li>
                    <li>AI の精度や性能の話</li>
                </ul>
                <p>を扱いません。</p>

                <p>扱うのはただ一つです。</p>

                <blockquote>
                    <strong>AIと一緒に考えるとき、<br>
                        どこから先は人が引き受けるべきか</strong>
                </blockquote>

                <h2>前提：これは「設計」ではなく「ガイド」です</h2>

                <p>ここで書かれている内容は、</p>
                <ul>
                    <li>ルールではありません</li>
                    <li>実装仕様ではありません</li>
                    <li>判断基準を強制するものでもありません</li>
                </ul>

                <p>これは、<br>
                    <strong>AI時代に人が壊れないための理解のガイド</strong>です。
                </p>

                <h2>1. AIは「不確実性を共有できない」</h2>

                <p>人間同士なら、自然に起きることがあります。</p>
                <ul>
                    <li>一緒に悩む</li>
                    <li>一緒に賭ける</li>
                    <li>一緒に不安を抱える</li>
                    <li>一緒に責任を引き受ける</li>
                </ul>

                <p>AIは、これらを <strong>構造的にできません</strong>。</p>

                <p>AIは不確実性を「扱う」ことはできても、<br>
                    <strong>不確実性を一緒に引き受けることはできない</strong>。
                </p>

                <p>だから、</p>
                <blockquote>
                    不確実な選択を後押しするのは、人間の役割です。
                </blockquote>

                <h2>2. AIの回答は整っているが、不確実性が省略されている</h2>

                <p>AIの回答は、</p>
                <ul>
                    <li>滑らかで</li>
                    <li>迷いがなく</li>
                    <li>もっともらしい</li>
                </ul>

                <p>しかし、その裏側には、</p>
                <ul>
                    <li>迷い</li>
                    <li>不安</li>
                    <li>賭け</li>
                    <li>リスク</li>
                    <li>責任</li>
                </ul>

                <p>が <strong>含まれていません</strong>。</p>

                <p>必要なときには、<br>
                    次の事実を思い出す必要があります。</p>

                <blockquote>
                    <strong>AIは不確実性を省略する</strong>
                </blockquote>

                <p>これは欠陥ではなく、性質です。</p>

                <h2>3. AIは「判断を閉じてよいか」を自分で決められない</h2>

                <p>AIは、自分の出力が</p>
                <ul>
                    <li>参考として使われるのか</li>
                    <li>行動の根拠になるのか</li>
                    <li>誰かの判断を代替してしまうのか</li>
                </ul>

                <p>を観測できません。</p>

                <p>そのため、</p>
                <ul>
                    <li>責任が分散したら閉じられない</li>
                    <li>取消できないなら閉じられない</li>
                    <li>社会的文脈が立ち上がったら閉じられない</li>
                </ul>

                <p>といった条件を、<br>
                    <strong>構造として持つ必要があります</strong>。
                </p>

                <p>この考え方は<br>
                    <strong>Decision Closure（判断閉路構造）</strong> として整理されています。
                </p>

                <h2>4. 人間にも「分からないランプ」が必要</h2>

                <p>AIには idk-lamp という考え方があります。</p>

                <p>しかし本当は、<br>
                    <strong>人間にも必要</strong>です。
                </p>

                <ul>
                    <li>今は判断できない</li>
                    <li>今は決められない</li>
                    <li>今は不確実性が大きすぎる</li>
                </ul>

                <p>これを、<br>
                    自分自身や周囲に伝えるためのシグナル。</p>

                <blockquote>
                    人間が「分からない」と言えることは、<br>
                    AI時代の重要なスキルです。
                </blockquote>

                <h2>5. AIの提案は「行動の責任」を肩代わりしない</h2>

                <p>行動のレイヤーには、<br>
                    次の3つの軸しかありません。</p>

                <ul>
                    <li>知っている / 知らない</li>
                    <li>提案のまま行動した / 人が判断した</li>
                    <li>人間自身もギブアップした</li>
                </ul>

                <p>つまり、</p>
                <blockquote>
                    <strong>行動の責任は常に人間にあります</strong>
                </blockquote>

                <p>AIは行動の共犯者にはなれません。</p>

                <h2>6. AIは「人間の価値」を知らない</h2>

                <p>AIは価値判断を持ちません。</p>

                <ul>
                    <li>何を大切にするか</li>
                    <li>何を失いたくないか</li>
                    <li>どんな未来を選ぶか</li>
                    <li>どんなリスクを許容するか</li>
                </ul>

                <p>これらは、<br>
                    <strong>人間固有の領域</strong>です。
                </p>

                <p>AIは価値を推測することはできても、<br>
                    <strong>共有することはできません</strong>。
                </p>

                <h2>7. AIは補助であって、代替ではない</h2>

                <p>AIは、</p>
                <ul>
                    <li>判断材料を提供できる</li>
                    <li>視点を増やせる</li>
                    <li>思考を整理できる</li>
                </ul>

                <p>しかし、</p>
                <ul>
                    <li>背中を押さない</li>
                    <li>賭けに参加しない</li>
                    <li>責任を持たない</li>
                </ul>

                <p>だからこそ、</p>
                <blockquote>
                    <strong>最終判断は人間が閉じるべきです</strong>
                </blockquote>

                <p>それは責任ではなく、<br>
                    <strong>価値を選ぶ行為</strong>だからです。
                </p>
            </section>

            <!-- Chapter 1: 00_overview.ja.md -->
            <section class="chapter" id="chapter-1">
                <h1>1. AI と人の境界の全体像</h1>

                <p>このドキュメントは、<br>
                    <strong>ai-human-boundary</strong> が扱う「境界」の全体像をまとめたものです。
                </p>

                <p>README は“入口”として最低限のガイドを示し、<br>
                    ここではその裏側にある <strong>構造</strong> を整理します。</p>

                <h2>1. 全体構造（レイヤー構造の地図）</h2>

                <p>AI と人が一緒に価値を選ぶとき、<br>
                    関係は次のような多層構造になります。</p>

                <p>
                    価値（VCDesign）<br>
                    ↓<br>
                    人間の意思決定レイヤー（不確実性の扱い）<br>
                    ├─ 人間側の idk-lamp（判断を閉じられないシグナル）<br>
                    └─ 不確実性のメタ認知（AIは不確実性を省略する）<br>
                    ↓<br>
                    AI＋人 → 行動（運用レイヤー）<br>
                    ├─ 知っている / 知らない<br>
                    ├─ 提案のまま / 人が判断<br>
                    └─ 人もギブアップ<br>
                    ↓<br>
                    Decision Closure（AIが判断を閉じてよいか）<br>
                    ├─ 5ステップ（責任・取消・可逆性・連鎖・社会文脈）<br>
                    └─ Transition（途中反転）<br>
                    ↓<br>
                    BOA（世界の境界）
                </p>

                <p>コード</p>

                <p>このリポジトリが扱うのは、<br>
                    <strong>Decision Closure より上の層（人間の意思決定レイヤー〜価値）</strong> です。
                </p>

                <hr>

                <h2>2. このリポジトリが扱う領域</h2>

                <h3>◆ 2.1 人間の意思決定レイヤー</h3>
                <p>AIと人が一緒に考えるとき、<br>
                    人間側には次の2つの構造が必要になります。</p>

                <h3>● 人間側の idk-lamp</h3>
                <ul>
                    <li>今は判断できない</li>
                    <li>今は決められない</li>
                    <li>今は不確実性が大きすぎる</li>
                </ul>

                <p>これを周囲に伝えるためのシグナル。</p>

                <p>AIに idk-lamp が必要だったように、<br>
                    人間にも同じものが必要になります。</p>

                <h3>● 不確実性のメタ認知</h3>
                <p>AIの回答は滑らかで整っているが、<br>
                    <strong>不確実性が省略されている</strong>。
                </p>

                <p>そのため人間は必要なときに、</p>

                <blockquote>
                    「AIは不確実性を共有できない」
                </blockquote>

                <p>という事実を思い出す必要があります。</p>

                <hr>

                <h3>◆ 2.2 行動レイヤー（AI＋人 → 行動）</h3>

                <p>行動の責任は常に人間にあります。<br>
                    その構造は次の3軸で表せます。</p>

                <ol>
                    <li><strong>知っている / 知らない</strong></li>
                    <li><strong>提案のまま行動した / 人が判断した</strong></li>
                    <li><strong>人間自身もギブアップした</strong></li>
                </ol>

                <p>この3軸は、<br>
                    AIと人が協力して行動する際の“最小構造”です。</p>

                <hr>

                <h2>3. Decision Closure との関係</h2>

                <p>Decision Closure（判断閉路構造）は、<br>
                    <strong>AIが判断を閉じてよいか</strong> を決めるための構造です。
                </p>

                <ul>
                    <li>責任主体が1人か</li>
                    <li>心理的取消に依存していないか</li>
                    <li>物理的に取り消せるか</li>
                    <li>行動が連鎖しないか</li>
                    <li>社会的文脈を帯びていないか</li>
                </ul>

                <p>これらの条件が破綻すると、<br>
                    AIは判断を閉じず **Human-Closed** になります。</p>

                <p>このリポジトリは、<br>
                    Decision Closure の“外側”にある<br>
                    <strong>人間の意思決定の境界</strong>を扱います。
                </p>

                <hr>

                <h2>4. BOA（世界の境界）との関係</h2>

                <p>BOA は「世界の境界」を定義する層であり、<br>
                    AI がどこまで踏み込めるかの外枠を決めます。</p>

                <ul>
                    <li>何が AI の責任か</li>
                    <li>何が人間の責任か</li>
                    <li>どこまでが AI の領域か</li>
                </ul>

                <p>Decision Closure は BOA の上に乗り、<br>
                    ai-human-boundary はそのさらに上に位置します。</p>

                <hr>

                <h2>5. このリポジトリの目的</h2>

                <ul>
                    <li>AIと人が一緒に価値を選ぶための“境界”を整理する</li>
                    <li>AI時代に人が壊れないための理解のガイドを残す</li>
                    <li>Decision Closure の外側にある「人間の役割」を明確にする</li>
                </ul>

                <p>これは設計でも仕様でもなく、<br>
                    <strong>人間のためのガイド</strong>です。
                </p>

                <hr>

                <h2>6. 推奨される読み順</h2>

                <p>
                    1. README<br>
                    2. 00_overview（この文書）<br>
                    3. human-idk-lamp<br>
                    4. uncertainty<br>
                    5. action-layer<br>
                    6. relationship-with-decision-closure
                </p>

                <hr>

                <h2>7. 最後に</h2>

                <p>AIが賢くなるほど、<br>
                    人間が「決めなくてよい理由」は増えていきます。</p>

                <p>しかし、</p>

                <blockquote>
                    <strong>価値を選ぶのは、常に人間の役割である</strong>
                </blockquote>

                <p>この境界を忘れないために、<br>
                    このリポジトリは存在します。</p>
            </section>

            <!-- Chapter 2: 01_human-idk-lamp.ja.md -->
            <section class="chapter" id="chapter-2">
                <h1>2. 人間側の「分からないランプ」</h1>

                <p>この文書は、<br>
                    <strong>人間にも idk-lamp（判断を閉じられないシグナル）が必要である</strong><br>
                    という考え方を整理したものです。
                </p>

                <p>AI に idk-lamp が必要だったように、<br>
                    AI 時代の人間にも同じ構造が必要になります。</p>

                <hr>

                <h2>1. なぜ「人間側の idk-lamp」が必要なのか</h2>

                <p>AI と人が一緒に考えるとき、<br>
                    人間はしばしば次のような状況に置かれます。</p>

                <ul>
                    <li>判断材料はあるが、決めきれない</li>
                    <li>不確実性が大きすぎる</li>
                    <li>未来の影響が読めない</li>
                    <li>責任の重さが大きい</li>
                    <li>価値の選択が絡む</li>
                </ul>

                <p>しかし、人間はこれを <strong>黙って抱え込んでしまう</strong> ことが多い。</p>

                <p>その結果、</p>

                <ul>
                    <li>無理に決断してしまう</li>
                    <li>AI の提案をそのまま採用してしまう</li>
                    <li>本当は判断できないのに「できるふり」をしてしまう</li>
                </ul>

                <p>という問題が起きる。</p>

                <p>これを防ぐために必要なのが、<br>
                    <strong>人間側の idk-lamp</strong> です。
                </p>

                <hr>

                <h2>2. 人間側の idk-lamp が示すもの</h2>

                <p>人間側の idk-lamp は、次の状態を示します。</p>

                <ul>
                    <li>今は判断できない</li>
                    <li>今は決められない</li>
                    <li>今は不確実性が大きすぎる</li>
                    <li>今は責任を引き受けられない</li>
                    <li>今は選択の価値を決められない</li>
                </ul>

                <p>これは弱さではなく、<br>
                    <strong>意思決定の健全性を守るためのシグナル</strong>です。
                </p>

                <hr>

                <h2>3. 人間同士では自然に共有される「不確実性」</h2>

                <p>人間同士の会話では、<br>
                    不確実性は“空気”として自然に共有されます。</p>

                <ul>
                    <li>相手の迷い</li>
                    <li>相手の不安</li>
                    <li>相手の責任感</li>
                    <li>相手の賭けの感覚</li>
                    <li>相手の価値観の揺れ</li>
                </ul>

                <p>これらは言葉にしなくても伝わる。</p>

                <p>だから人間同士は、<br>
                    <strong>不確実性を共有しながら意思決定できる</strong>。
                </p>

                <hr>

                <h2>4. 人＋AI では不確実性が共有されない</h2>

                <p>AI は構造的に次のことができません。</p>

                <ul>
                    <li>一緒に悩む</li>
                    <li>一緒に賭ける</li>
                    <li>一緒に責任を持つ</li>
                    <li>一緒に不安を抱える</li>
                    <li>一緒に未来を想像する</li>
                </ul>

                <p>つまり、AI は <strong>不確実性の共犯者になれない</strong>。</p>

                <p>そのため、人間が「分からない」と言わない限り、<br>
                    AI はその不確実性を認識できない。</p>

                <hr>

                <h2>5. 人間側の idk-lamp が果たす役割</h2>

                <p>人間側の idk-lamp は、次の役割を持ちます。</p>

                <h3>● ① 自分自身へのシグナル</h3>
                <p>「今は決められない」という事実を<br>
                    自分で認識するためのメタ認知。</p>

                <h3>● ② AI へのシグナル</h3>
                <p>AI に対して<br>
                    「判断を閉じる段階ではない」<br>
                    ことを伝える。</p>

                <h3>● ③ 周囲（人間）へのシグナル</h3>
                <p>チームや関係者に<br>
                    「今は判断を保留すべき」<br>
                    という状態を共有する。</p>

                <h3>● ④ 責任の暴走を防ぐ</h3>
                <p>判断を急がせる圧力から<br>
                    自分を守るための境界。</p>

                <hr>

                <h2>6. どんなときに「人間側の idk-lamp」を点灯すべきか</h2>

                <p>次のような場面では、<br>
                    積極的に idk-lamp を点灯すべきです。</p>

                <ul>
                    <li>判断の根拠が薄い</li>
                    <li>未来の影響が大きい</li>
                    <li>価値の選択が絡む</li>
                    <li>自分の状態が不安定</li>
                    <li>情報が足りない</li>
                    <li>責任が重すぎる</li>
                    <li>AI の回答が滑らかすぎて不安</li>
                </ul>

                <p>特に最後の項目は重要です。</p>

                <blockquote>
                    AI の回答が整っているほど、<br>
                    人間は「不確実性が省略されている」ことを忘れやすい。
                </blockquote>

                <hr>

                <h2>7. 人間側の idk-lamp の具体的な表現例</h2>

                <p>これはルールではなく、<br>
                    あくまで“表現の例”です。</p>

                <ul>
                    <li>「今は判断できません」</li>
                    <li>「もう少し考える時間が必要です」</li>
                    <li>「この不確実性は自分では扱えません」</li>
                    <li>「これは価値の選択なので、すぐには決められません」</li>
                    <li>「判断を保留します」</li>
                </ul>

                <p>重要なのは、<br>
                    <strong>判断を止めることを恥じない</strong> こと。
                </p>

                <hr>

                <h2>8. 人間側の idk-lamp と Decision Closure の関係</h2>

                <p>Decision Closure は<br>
                    <strong>AI が判断を閉じてよいか</strong> を決める構造。
                </p>

                <p>人間側の idk-lamp は<br>
                    <strong>人間が判断を閉じてよいか</strong> を決めるシグナル。
                </p>

                <p>両者は次のように補完し合う。</p>

                <p>
                    AI：閉じてはいけない判断を閉じない（Decision Closure）<br>
                    人：閉じられない判断を閉じない（human-idk-lamp）
                </p>

                <p>コード</p>

                <p>この二つが揃って初めて、<br>
                    AI と人の協働が健全になる。</p>

                <hr>

                <h2>9. まとめ（短い版）</h2>

                <ul>
                    <li>人間にも「分からないランプ」が必要</li>
                    <li>人間同士では自然に共有される不確実性は、AIとは共有されない</li>
                    <li>AIは不確実性の共犯者になれない</li>
                    <li>判断できない状態を示すことは弱さではなく境界</li>
                    <li>人間側の idk-lamp は、意思決定の健全性を守るための構造</li>
                    <li>Decision Closure と対になる存在</li>
                </ul>

                <hr>

                <h2>10. 次に読むべき文書</h2>

                <ul>
                    <li>02_uncertainty.ja.md（不確実性の扱い）</li>
                    <li>03_action-layer.ja.md（行動レイヤーの3軸）</li>
                    <li>04_relationship-with-decision-closure.ja.md（DCとの関係）</li>
                </ul>
            </section>

            <!-- Chapter 3: 02_uncertainty.ja.md -->
            <section class="chapter" id="chapter-3">
                <h1>3. 不確実性の扱い</h1>

                <p>この文書は、<br>
                    <strong>AI と人が一緒に考えるときに最も重要になる「不確実性」</strong><br>
                    について整理したものです。
                </p>

                <p>AI は不確実性を「扱う」ことはできますが、<br>
                    <strong>不確実性を“共有する”ことはできません</strong>。
                </p>

                <p>この違いが、AI と人の境界を決定づけます。</p>

                <hr>

                <h2>1. 不確実性とは何か</h2>

                <p>不確実性とは、次のような状態を指します。</p>

                <ul>
                    <li>未来が読めない</li>
                    <li>結果が保証されない</li>
                    <li>判断材料が揃っていない</li>
                    <li>価値の選択が絡む</li>
                    <li>リスクがゼロにならない</li>
                </ul>

                <p>人間の意思決定は、<br>
                    常にこの不確実性の中で行われています。</p>

                <hr>

                <h2>2. 人間は「不確実性を共有できる」</h2>

                <p>人間同士の意思決定には、<br>
                    次のような“共有”が自然に存在します。</p>

                <ul>
                    <li>相手も迷っている</li>
                    <li>相手も不安を抱えている</li>
                    <li>相手も責任を感じている</li>
                    <li>相手も賭けに参加している</li>
                    <li>相手も未来を読めない</li>
                </ul>

                <p>つまり、人間同士は <strong>不確実性の共犯者</strong> になれる。</p>

                <p>この「共犯性」があるからこそ、<br>
                    人間は不確実な選択を後押しし合える。</p>

                <hr>

                <h2>3. AI は「不確実性の共犯者になれない」</h2>

                <p>AI は構造的に次のことができません。</p>

                <ul>
                    <li>一緒に悩む</li>
                    <li>一緒に賭ける</li>
                    <li>一緒に責任を持つ</li>
                    <li>一緒に不安を抱える</li>
                    <li>一緒に未来を想像する</li>
                </ul>

                <p>AI は不確実性を“計算”することはできても、<br>
                    <strong>不確実性を“一緒に抱える”ことはできない</strong>。
                </p>

                <p>そのため、AI は次の領域に踏み込めません。</p>

                <ul>
                    <li>背中を押す</li>
                    <li>賭けを促す</li>
                    <li>勇気を与える</li>
                    <li>リスクを共に負う</li>
                </ul>

                <p>これらはすべて <strong>人間固有の領域</strong> です。</p>

                <hr>

                <h2>4. AI の回答は「不確実性が省略されている」</h2>

                <p>AI の回答は滑らかで整っていますが、<br>
                    その裏側には次のものが含まれていません。</p>

                <ul>
                    <li>迷い</li>
                    <li>不安</li>
                    <li>賭け</li>
                    <li>責任</li>
                    <li>価値観</li>
                    <li>未来への恐れ</li>
                </ul>

                <p>つまり、AI の回答は <strong>不確実性が“抜け落ちた状態”</strong> で提示される。</p>

                <p>これは欠陥ではなく、<br>
                    <strong>AI の構造的な性質</strong>です。
                </p>

                <hr>

                <h2>5. 不確実性が省略されると何が起きるか</h2>

                <p>人間は AI の滑らかな回答を見て、<br>
                    次のような誤解をしやすくなります。</p>

                <ul>
                    <li>「これは確実なのだろう」</li>
                    <li>「迷いがないなら正しいのだろう」</li>
                    <li>「AI が言うなら大丈夫だろう」</li>
                </ul>

                <p>しかし実際には、</p>

                <blockquote>
                    <strong>AI は不確実性を省略しているだけで、</strong><br>
                    <strong>その判断の“重さ”を共有していない。</strong>
                </blockquote>

                <p>このギャップが、<br>
                    人間の意思決定を危うくする。</p>

                <hr>

                <h2>6. 不確実性を扱うのは人間の役割</h2>

                <p>不確実性を扱うには、次の要素が必要です。</p>

                <ul>
                    <li>勇気</li>
                    <li>価値観</li>
                    <li>責任</li>
                    <li>直感</li>
                    <li>経験</li>
                    <li>未来への覚悟</li>
                </ul>

                <p>これらはすべて <strong>人間固有の能力</strong> であり、<br>
                    AI が代替できる領域ではありません。</p>

                <p>だからこそ、</p>

                <blockquote>
                    <strong>不確実性を選ぶ判断は、人間が閉じるべき判断</strong><br>
                    であり、AI が閉じてはいけない。
                </blockquote>

                <hr>

                <h2>7. 不確実性と「人間側の idk-lamp」</h2>

                <p>不確実性が大きいとき、<br>
                    人間は次のような状態になります。</p>

                <ul>
                    <li>判断できない</li>
                    <li>決められない</li>
                    <li>未来が怖い</li>
                    <li>責任が重い</li>
                    <li>情報が足りない</li>
                </ul>

                <p>この状態を示すために必要なのが、<br>
                    <strong>人間側の idk-lamp</strong> です。
                </p>

                <p>AI が idk-lamp を持つように、<br>
                    人間も「今は閉じられない」というシグナルを<br>
                    自分と周囲に示す必要がある。</p>

                <hr>

                <h2>8. 不確実性と Decision Closure の関係</h2>

                <p>Decision Closure は<br>
                    <strong>AI が判断を閉じてよいか</strong> を決める構造。
                </p>

                <p>不確実性が大きい判断は、<br>
                    Decision Closure の 5 ステップのどこかで必ず破綻する。</p>

                <ul>
                    <li>責任が分散する</li>
                    <li>取消できない</li>
                    <li>社会文脈が立ち上がる</li>
                    <li>行動が連鎖する</li>
                </ul>

                <p>つまり、</p>

                <blockquote>
                    <strong>不確実性が大きい判断は、AI が閉じてはいけない判断</strong>
                </blockquote>

                <p>となる。</p>

                <hr>

                <h2>9. まとめ（短い版）</h2>

                <ul>
                    <li>不確実性は人間の意思決定の中心</li>
                    <li>人間同士は不確実性を共有できる</li>
                    <li>AI は不確実性の共犯者になれない</li>
                    <li>AI の回答は不確実性が省略されている</li>
                    <li>不確実性を選ぶ判断は人間の領域</li>
                    <li>不確実性が大きいときは人間側の idk-lamp が必要</li>
                    <li>Decision Closure は不確実性の大きい判断を AI から外す構造</li>
                </ul>

                <hr>

                <h2>10. 次に読むべき文書</h2>

                <ul>
                    <li><a href="#chapter-4">03_action-layer.ja.md（行動レイヤーの3軸）</a></li>
                    <li><a href="#chapter-5">04_relationship-with-decision-closure.ja.md（DCとの関係）</a></li>
                </ul>
            </section>

            <!-- Chapter 4: 03_action-layer.ja.md -->
            <section class="chapter" id="chapter-4">
                <h1>4. 行動レイヤーの3軸</h1>

                <p>この文書は、<br>
                    <strong>AI と人が協力して行動を決めるときに必要となる「行動レイヤー」</strong><br>
                    を整理したものです。
                </p>

                <p>行動レイヤーは、Decision Closure の外側にあり、<br>
                    AI と人が「一緒に価値を選ぶ」ための最小構造です。</p>

                <hr>

                <h2>1. 行動レイヤーとは何か</h2>

                <p>AI と人が対話し、何かを決めようとするとき、<br>
                    最終的には <strong>行動</strong> に落ちていきます。
                </p>

                <p>しかし、行動の責任は常に人間にあります。</p>

                <p>そのため、行動レイヤーには次の3つの軸が存在します。</p>

                <p>知っている / 知らない</p>

                <p>提案のまま行動した / 人が判断した</p>

                <p>人間自身もギブアップした</p>

                <p>コード</p>

                <p>この3軸は、<br>
                    AI と人が協働する際の“最小構造”です。</p>

                <hr>

                <h2>2. 軸①：知っている / 知らない</h2>

                <p>行動に関わる知識は、<br>
                    人間側に次の2種類があります。</p>

                <h3>● 知っている</h3>
                <ul>
                    <li>手順を知っている</li>
                    <li>経験がある</li>
                    <li>何をすべきか理解している</li>
                </ul>

                <p>この場合、AI の役割は<br>
                    <strong>思い出し・整理・確認</strong> に近い。
                </p>

                <h3>● 知らない</h3>
                <ul>
                    <li>初めての領域</li>
                    <li>手順が分からない</li>
                    <li>判断材料が足りない</li>
                </ul>

                <p>この場合、AI の提案は<br>
                    <strong>新しい行動のきっかけ</strong> になる。
                </p>

                <p>ただし、知らない領域での行動は<br>
                    <strong>不確実性が大きい</strong>ため、<br>
                    最終判断は必ず人間が行う必要がある。
                </p>

                <hr>

                <h2>3. 軸②：提案のまま行動した / 人が判断した</h2>

                <p>AI の提案に対して、人間は次のどちらかを選ぶ。</p>

                <h3>● 提案のまま行動した</h3>
                <ul>
                    <li>AI の提案をそのまま採用</li>
                    <li>判断を省略した状態</li>
                    <li>リスクの理解が浅くなりやすい</li>
                </ul>

                <h3>● 人が判断した</h3>
                <ul>
                    <li>AI の提案を材料として扱う</li>
                    <li>自分の価値観で選ぶ</li>
                    <li>行動の責任を自分で引き受ける</li>
                </ul>

                <p>重要なのは、</p>

                <blockquote>
                    <strong>AI は行動の責任を肩代わりできない</strong>
                </blockquote>

                <p>という点。</p>

                <p>AI は提案できるが、<br>
                    <strong>選択の重さを共有できない</strong>。
                </p>

                <hr>

                <h2>4. 軸③：人間自身もギブアップした</h2>

                <p>行動レイヤーで最も重要な軸。</p>

                <p>人間自身が次のような状態になることがある。</p>

                <ul>
                    <li>判断できない</li>
                    <li>決められない</li>
                    <li>不確実性が大きすぎる</li>
                    <li>責任が重すぎる</li>
                    <li>未来が怖い</li>
                </ul>

                <p>これは弱さではなく、<br>
                    <strong>人間の意思決定の自然な限界</strong>。
                </p>

                <p>この状態は、<br>
                    <strong>人間側の idk-lamp</strong> を点灯すべき場面。
                </p>

                <p>そして、</p>

                <blockquote>
                    <strong>人間がギブアップする判断は、</strong><br>
                    <strong>AI が閉じてはいけない判断でもある。</strong>
                </blockquote>

                <hr>

                <h2>5. 行動レイヤーの3軸が示すもの</h2>

                <p>この3軸は、<br>
                    AI と人の協働における“境界”を明確にする。</p>

                <p>知っている / 知らない<br>
                    → 行動の難易度と不確実性</p>

                <p>提案のまま / 人が判断<br>
                    → 判断主体と責任の所在</p>

                <p>人もギブアップ<br>
                    → 人間の限界と idk-lamp の必要性</p>

                <p>コード</p>

                <p>この3つが揃うことで、<br>
                    AI と人の協働が健全になる。</p>

                <hr>

                <h2>6. 行動レイヤーと Decision Closure の関係</h2>

                <p>Decision Closure は<br>
                    <strong>AI が判断を閉じてよいか</strong> を決める構造。
                </p>

                <p>行動レイヤーは<br>
                    <strong>人間が行動を引き受けるための構造</strong>。
                </p>

                <p>両者は次のように補完し合う。</p>

                <p>Decision Closure：<br>
                    AI が閉じてはいけない判断を外す</p>

                <p>Action Layer：<br>
                    人間が行動を引き受けるための最小構造を整える</p>

                <p>コード</p>

                <p>つまり、</p>

                <blockquote>
                    <strong>AI は閉じない</strong><br>
                    <strong>人は引き受ける</strong><br>
                    <strong>その境界を支えるのが行動レイヤー</strong>
                </blockquote>

                <p>という関係になる。</p>

                <hr>

                <h2>7. まとめ（短い版）</h2>

                <ul>
                    <li>行動レイヤーは AI＋人 → 行動 の最小構造</li>
                    <li>3軸は「知識」「判断主体」「人間の限界」</li>
                    <li>行動の責任は常に人間にある</li>
                    <li>人間がギブアップする判断は、AI も閉じてはいけない</li>
                    <li>Decision Closure と行動レイヤーは補完関係</li>
                </ul>

                <hr>

                <h2>8. 次に読むべき文書</h2>

                <ul>
                    <li><a href="#chapter-5">04_relationship-with-decision-closure.ja.md（DCとの関係）</a></li>
                </ul>
            </section>

            <!-- Chapter 5: 04_relationship-with-decision-closure.ja.md -->
            <section class="chapter" id="chapter-5">
                <h1>5. Decision Closure との関係</h1>

                <p>この文書は、<br>
                    <strong>ai-human-boundary（人間の境界ガイド）</strong> と<br>
                    <strong>Decision Closure（AI の判断閉路構造）</strong><br>
                    の関係を整理したものです。
                </p>

                <p>両者は目的も扱う領域も異なりますが、<br>
                    互いに補完し合う構造になっています。</p>

                <hr>

                <h2>1. まず結論：両者は「上下関係」ではなく「役割の違い」</h2>

                <p>ai-human-boundary：<br>
                    人間がどこまで引き受けるか（価値・不確実性・判断の限界）</p>

                <p>Decision Closure：<br>
                    AI がどこまで踏み込めるか（判断を閉じてよいか）</p>

                <p>コード</p>

                <p>つまり、</p>

                <ul>
                    <li><strong>人間の境界</strong>を扱うのが ai-human-boundary</li>
                    <li><strong>AI の境界</strong>を扱うのが Decision Closure</li>
                </ul>

                <p>という関係。</p>

                <p>どちらが上位という話ではなく、<br>
                    <strong>両者が揃って初めて AI＋人 の協働が成立する</strong>。
                </p>

                <hr>

                <h2>2. 両者が扱う領域の違い</h2>

                <h3>◆ ai-human-boundary が扱う領域</h3>
                <ul>
                    <li>人間の不確実性</li>
                    <li>人間側の idk-lamp</li>
                    <li>行動の責任</li>
                    <li>価値の選択</li>
                    <li>人間の限界</li>
                    <li>AI と人の協働の“外側”の構造</li>
                </ul>

                <p>これは <strong>人間の意思決定レイヤー</strong> に属する。</p>

                <hr>

                <h3>◆ Decision Closure が扱う領域</h3>
                <ul>
                    <li>AI が判断を閉じてよいか</li>
                    <li>責任の所在</li>
                    <li>可逆性</li>
                    <li>行動の連鎖</li>
                    <li>社会的文脈</li>
                    <li>途中反転（Transition）</li>
                </ul>

                <p>これは <strong>AI の判断閉路レイヤー</strong> に属する。</p>

                <hr>

                <h2>3. 両者の境界を図にするとこうなる</h2>

                <p>
                    価値（VCDesign）<br>
                    ↓<br>
                    人間の意思決定レイヤー（ai-human-boundary）<br>
                    ├─ 人間側の idk-lamp<br>
                    ├─ 不確実性のメタ認知<br>
                    └─ 行動レイヤーの3軸<br>
                    ↓<br>
                    AI の判断閉路レイヤー（Decision Closure）<br>
                    ├─ 5ステップ<br>
                    └─ Transition<br>
                    ↓<br>
                    BOA（世界の境界）
                </p>

                <p>コード</p>

                <p>ai-human-boundary は <strong>Decision Closure の外側</strong> にあり、<br>
                    人間がどう立つかを扱う。</p>

                <p>Decision Closure は <strong>AI の内側</strong> にあり、<br>
                    AI がどこまで踏み込めるかを扱う。</p>

                <hr>

                <h2>4. なぜこの2つが必要なのか</h2>

                <p>AI と人が協働するには、<br>
                    次の2つの境界が必要になる。</p>

                <h3>● ① AI が踏み込んではいけない境界</h3>
                <p>→ Decision Closure が担当<br>
                    → 「AI はここで判断を閉じてはいけない」</p>

                <h3>● ② 人間が引き受けるべき境界</h3>
                <p>→ ai-human-boundary が担当<br>
                    → 「ここから先は人間が決める」</p>

                <p>この2つが揃って初めて、<br>
                    AI と人の協働が <strong>安全で、健全で、価値に沿ったもの</strong> になる。
                </p>

                <hr>

                <h2>5. 両者の関係を一言で言うと</h2>

                <blockquote>
                    <strong>Decision Closure は AI の“止まる構造”。</strong><br>
                    <strong>ai-human-boundary は 人間の“立つ構造”。</strong>
                </blockquote>

                <p>AI が止まるだけでは不十分で、<br>
                    人間がどこに立つかが必要。</p>

                <p>人間が立つだけでは不十分で、<br>
                    AI がどこで止まるかが必要。</p>

                <hr>

                <h2>6. 両者が補完し合う具体例</h2>

                <h3>● ケース1：不確実性が大きい判断</h3>
                <ul>
                    <li>人間側：idk-lamp が点灯</li>
                    <li>AI側：Decision Closure が Human-Closed を返す</li>
                </ul>

                <p>→ <strong>両者が同じ方向を向く</strong></p>

                <hr>

                <h3>● ケース2：人間がギブアップしている</h3>
                <ul>
                    <li>人間側：判断できない</li>
                    <li>AI側：責任が分散しているため閉じられない</li>
                </ul>

                <p>→ <strong>AI が人間の限界を踏み越えない</strong></p>

                <hr>

                <h3>● ケース3：AI の提案が滑らかすぎる</h3>
                <ul>
                    <li>人間側：不確実性の省略をメタ認知</li>
                    <li>AI側：社会文脈が立ち上がり閉じられない</li>
                </ul>

                <p>→ <strong>誤った確信を避けられる</strong></p>

                <hr>

                <h2>7. 両者の違いを表にすると</h2>

                <table>
                    <thead>
                        <tr>
                            <th>項目</th>
                            <th>ai-human-boundary</th>
                            <th>Decision Closure</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>対象</td>
                            <td>人間</td>
                            <td>AI</td>
                        </tr>
                        <tr>
                            <td>扱うもの</td>
                            <td>不確実性・価値・責任の引き受け</td>
                            <td>判断の可否・可逆性・社会文脈</td>
                        </tr>
                        <tr>
                            <td>目的</td>
                            <td>人間が壊れないためのガイド</td>
                            <td>AI が踏み越えないための構造</td>
                        </tr>
                        <tr>
                            <td>形式</td>
                            <td>ガイド / 理解</td>
                            <td>構造 / ルール</td>
                        </tr>
                        <tr>
                            <td>出力</td>
                            <td>人間の立ち位置</td>
                            <td>AI-Closed / Human-Closed</td>
                        </tr>
                    </tbody>
                </table>

                <hr>

                <h2>8. まとめ（短い版）</h2>

                <ul>
                    <li>ai-human-boundary は「人間の境界」</li>
                    <li>Decision Closure は「AI の境界」</li>
                    <li>両者は上下ではなく役割が違う</li>
                    <li>不確実性は人間が扱う</li>
                    <li>判断の閉路は AI が扱う</li>
                    <li>2つが揃って初めて AI＋人 の協働が成立する</li>
                </ul>
            </section>

        </div>

        <nav class="story-nav">
            <a href="#prelude" class="story-dot" data-title="ai-human-boundary"
                aria-label="Jump to ai-human-boundary"></a>
            <a href="#chapter-1" class="story-dot" data-title="1. 全体像" aria-label="Jump to Chapter 1"></a>
            <a href="#chapter-2" class="story-dot" data-title="2. 人間側の「分からないランプ」" aria-label="Jump to Chapter 2"></a>
            <a href="#chapter-3" class="story-dot" data-title="3. 不確実性の扱い" aria-label="Jump to Chapter 3"></a>
            <a href="#chapter-4" class="story-dot" data-title="4. 行動レイヤーの3軸" aria-label="Jump to Chapter 4"></a>
            <a href="#chapter-5" class="story-dot" data-title="5. Decision Closure との関係"
                aria-label="Jump to Chapter 5"></a>
        </nav>

        <footer>
            © 2026 idk-lamp
        </footer>
    </main>
</body>

</html>